{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature 4: Bigram Counts\n",
      "\n",
      "This feature considers the frequency of two words at a time, i.e. bigrams. The following classification algorithms are covered:\n",
      "\n",
      "<ul>\n",
      "    <li>K-Nearest Neighbours</li>\n",
      "    <li>Naive Bayes</li>\n",
      "    <li>Perceptron</li>\n",
      "    <li>Decision Tree (not viable)</li>\n",
      "    <li>Linear SVM</li>\n",
      "    <li>Stochastic Gradient Descent\n",
      "        <ul>\n",
      "            <li>Hinge Loss</li>\n",
      "            <li>Modified Huber Loss</li>\n",
      "        </ul>\n",
      "    </li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Initialization\n",
      "\n",
      "The code below loads the appropriate data. First set the appropriate location where the data resides using the `datapath` variable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set the path where the data resides\n",
      "datapath = \"../data/movies-english/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load train set\n",
      "train_set_location = \"{0}train\".format(datapath)\n",
      "train_set = datasets.load_files(train_set_location)\n",
      "\n",
      "# Load test set\n",
      "test_set_location = \"{0}test\".format(datapath)\n",
      "test_set = datasets.load_files(test_set_location)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some verifications:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Size of the training set\n",
      "print(len(train_set.data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2000\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Size of the test set\n",
      "print(len(test_set.data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Names of the two categories\n",
      "print(train_set.target_names)\n",
      "print(test_set.target_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['neg', 'pos']\n",
        "['neg', 'pos']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# An example train review\n",
      "demo_review_index = 720 # Change to view different reviews\n",
      "print(\"The review is {0}\".format(train_set.target_names[train_set.target[demo_review_index]]))\n",
      "print(train_set.data[demo_review_index])\n",
      "\n",
      "del demo_review_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The review is pos\n",
        "b\"I had the pleasure of viewing this beautiful film last night, with the wonderful addition of a question and answer session with the director following the viewing. I suspect that the first commenter has never lost a parent or someone very close to them in death. I have had many such losses, and this movie spoke to me. One of the major themes is how we don't deal with questions/issues/stories with our loved ones until it's too late--they're too incapacitated or dead before that happens. Talk to your loved ones, listen to and record their stories, tell people you love them, resolve differences. I loved the message that there are no mistakes. I love the director's portrayal of the relationship of the two daughters--as one of six siblings, it's clear to me he understood how complex those relationships are. His history as a cinematographer also comes through loud and clear--what a beautiful movie! The casting is outstanding--a film not to be missed!\"\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Data Transformation\n",
      "\n",
      "The following code transforms the documents into feature vectors depending on whether a particular word occurs in the document or not. The `CountVectorizer` from the `sklearn.feature_extraction.text` package is used for this purpose. In order for `CountVectorizer` to consider bigrams, the `ngram_range` parameter is set to `(2,2)`, i.e. the minimum and maximum value of 'n' for n-gram modeling are both 2."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the vectorizer\n",
      "bigram_count_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
      "\n",
      "# Fit training data and transform appropriately\n",
      "bigram_train_X = bigram_count_vectorizer.fit_transform(train_set.data)\n",
      "bigram_train_y = train_set.target\n",
      "\n",
      "# Transform test data according to learnt training vocabulary\n",
      "bigram_test_X = bigram_count_vectorizer.transform(test_set.data)\n",
      "bigram_test_y = test_set.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Length of feature vector: {0}\".format(bigram_train_X.shape[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Length of feature vector: 209871\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Function Setup\n",
      "\n",
      "The following code sets up a function to perform classification. It accepts an estimator object and calls the `fit()` method of that object to learn the training data, and then the `predict()` method, supplying the test data as a parameter. The predicted vectors for the test data are returned."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify(classifier):\n",
      "    classifier.fit(bigram_train_X, bigram_train_y)\n",
      "    predicted_y = classifier.predict(bigram_test_X)\n",
      "    \n",
      "    return predicted_y\n",
      "\n",
      "def select_classify(classifier, k):\n",
      "    \n",
      "    # First select\n",
      "    from sklearn.feature_selection import chi2, SelectKBest\n",
      "    selector = SelectKBest(chi2, k)\n",
      "    bigram_seltrain_X = selector.fit_transform(bigram_train_X, bigram_train_y)\n",
      "    \n",
      "    classifier.fit(bigram_seltrain_X, bigram_train_y)\n",
      "    predicted_y = classifier.predict(selector.transform(bigram_test_X))\n",
      "    \n",
      "    return predicted_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below now sets up a function to calculate accuracy values and report the same for the last performed classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy():\n",
      "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "\n",
      "    acc = accuracy_score(bigram_test_y, bigram_predict_y) * 100\n",
      "    print(\"Accuracy: {0}%\".format(acc))\n",
      "    print(classification_report(bigram_test_y, bigram_predict_y, target_names=test_set.target_names))\n",
      "    \n",
      "    return acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below sets up a function to evaluate a classifier's performance depending on the number of features supplied to it. It creates a plot of features vs. accuracy out of repeated runs of the supplied classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compare_feature_performance(classifier, classifier_name='Classifier'):\n",
      "    \n",
      "    from sklearn.metrics import accuracy_score\n",
      "    accuracies = []\n",
      "    kvals = logspace(1, 17, num=17, base=2.0)  # k = 2, 4, 8, 16, ...\n",
      "    kvals = append(kvals, [bigram_train_X.shape[1]])\n",
      "    for k in kvals:\n",
      "        bigram_predict_y = select_classify(classifier, k)\n",
      "        accuracies.append(accuracy_score(bigram_test_y, bigram_predict_y) * 100)\n",
      "    \n",
      "    plot(kvals, accuracies)\n",
      "    xscale('log')\n",
      "    xlim([0, bigram_train_X.shape[1]])\n",
      "    xlabel('Number of features')\n",
      "    ylabel('Accuracy (%)')\n",
      "    title('{0} Behaviour with Different no of Features'.format(classifier_name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}