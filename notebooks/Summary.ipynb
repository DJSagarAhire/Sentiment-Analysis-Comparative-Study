{
 "metadata": {
  "name": "Summary"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Machine Learning Techniques for Sentiment Analysis\n",
      "\n",
      "This is a comparative study of various machine learning algorithms for sentiment analysis, with different feature sets. This includes both classification and clustering algorithms.\n",
      "\n",
      "###Dataset\n",
      "\n",
      "The dataset used is a random selection of movie reviews from the [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/). The selection consists of:\n",
      "<ul>\n",
      "    <li> 2000 training reviews (1000 positive, 1000 negative) </li>\n",
      "    <li> 1000 testing reviews (500 positive, 500 negative) </li>\n",
      "</ul>\n",
      "\n",
      "The code outlined below, however, aims to be adaptable to any binary classification dataset.\n",
      "\n",
      "###Algorithms Covered\n",
      "\n",
      "####A: Classification\n",
      "\n",
      "The following classification algorithms are studied for this project:\n",
      "<ul>\n",
      "    <li>K-Nearest Neighbours</li>\n",
      "    <li>Naive Bayes</li>\n",
      "    <li>Perceptron</li>\n",
      "    <li>Decision Tree</li>\n",
      "    <li>Linear SVM</li>\n",
      "    <li>Stochastic Gradient Descent\n",
      "        <ul>\n",
      "            <li>Hinge Loss</li>\n",
      "            <li>Modified Huber Loss</li>\n",
      "        </ul>\n",
      "    </li>\n",
      "</ul>\n",
      "\n",
      "####B: Clustering\n",
      "\n",
      "Clustering algorithms are pending.\n",
      "\n",
      "###Features Covered\n",
      "\n",
      "The following features are studied for this project:\n",
      "<ul>\n",
      "    <li>Unigram Presence</li>\n",
      "    <li>Unigram Counts (In Progress)</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Organization of this Report\n",
      "\n",
      "This report is built out of ipython notebooks. Notebooks are divided by features considered. Each notebook uses several classifiers on the data and compares them. The overall final results can be found at the end of this notebook (pending).\n",
      "\n",
      "The following are the notebooks:\n",
      "\n",
      "<ol>\n",
      "    <li><code>Classification-Unigram-Presence</code></li>\n",
      "    <li><code>Classification-Unigram-Counts</code></li>\n",
      "</ol>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Final Results\n",
      "\n",
      "The results are summarised in the matrix below:\n",
      "\n",
      "<table>\n",
      "    <tr>\n",
      "        <th>Feature</th>\n",
      "        <th>K-Nearest</th>\n",
      "        <th>Naive Bayes</th>\n",
      "        <th>Perceptron</th>\n",
      "        <th>Decision Tree</th>\n",
      "        <th>SVM</th>\n",
      "        <th>SGD: Hinge Loss</th>\n",
      "        <th>SGD: Huber Loss</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td>Unigram Presence</td>\n",
      "        <td>75**</td>\n",
      "        <td>78**</td>\n",
      "        <td>78.30</td>\n",
      "        <td>62.80*</td>\n",
      "        <td>79.80</td>\n",
      "        <td>78.30*</td>\n",
      "        <td>78.10*</td>\n",
      "    </tr>\n",
      "</table>\n",
      "\n",
      "######* Feature and parameter selection pending\n",
      "######** Exact figures pending"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}